{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing some python codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from behavior_selection import behavior_selection\n",
    "from neural_matrix import neural_matrix\n",
    "from neuro_behavior_options import neuro_behavior_options\n",
    "from load_data import load_data\n",
    "\n",
    "# figurePath = '/Users/paulmiddlebrooks/Projects/ridgeregress/docs/'\n",
    "# bhvDataPath = '/Users/paulmiddlebrooks/Projects/neuro-behavior/data/processed_behavior/'\n",
    "# nrnDataPath = '/Users/paulmiddlebrooks/Projects/neuro-behavior/data/raw_ephys/'\n",
    "# saveDataPath = '/Users/paulmiddlebrooks/Projects/ridgeRegress/data/'\n",
    "figurePath = 'E:/Projects/ridgeregress/docs/'\n",
    "bhvDataPath = 'E:/Projects/neuro-behavior/data/processed_behavior/'\n",
    "nrnDataPath = 'E:/Projects/neuro-behavior/data/raw_ephys/'\n",
    "saveDataPath = 'E:/Projects/ridgeRegress/data/'\n",
    "\n",
    "\n",
    "animal = 'ag25290'\n",
    "sessionBhv = '112321_1'\n",
    "sessionNrn = '112321'\n",
    "\n",
    "if sessionBhv == '112321_1':\n",
    "    sessionSave = '112321'\n",
    "\n",
    "\n",
    "\n",
    "opts = neuro_behavior_options()\n",
    "\n",
    "nrnDataPath = nrnDataPath + 'animal_' + animal + '/' + sessionNrn + '/recording1/'\n",
    "\n",
    "bhvDataPath = join(bhvDataPath, 'animal_'+ animal)\n",
    "bhvFileName = 'behavior_labels_' + animal + '_' + sessionBhv + '.csv'\n",
    "opts.dataPath = bhvDataPath\n",
    "opts.fileName = bhvFileName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\neuro-behavior\\src\\load_data.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_window.loc[:,'Time'] = data_window['Time'] - data_window['Time'].iloc[0]\n"
     ]
    }
   ],
   "source": [
    "figurePath = join(figurePath, animal, sessionSave, 'figures', f'start {opts.collectStart} for {opts.collectFor}')\n",
    "\n",
    "if not os.path.exists(figurePath):\n",
    "    os.makedirs(figurePath)\n",
    "\n",
    "\n",
    "# data_full = pd.read_csv(join(opts.dataPath, opts.fileName))\n",
    "dataBhv = load_data(opts, 'behavior')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_nest_sleeping_or_irrelevant code -1.0 is not a valid behavior for this analysis\n",
      "\n",
      "\n",
      "Behavior 0.0: investigate_1\n",
      "274: allPossible\n",
      "274: andLongEnough\n",
      "201: andNotRepeated\n",
      "Percent valid: 73.4\n",
      "\n",
      "Behavior 1.0: investigate_2\n",
      "650: allPossible\n",
      "650: andLongEnough\n",
      "305: andNotRepeated\n",
      "Percent valid: 46.9\n",
      "\n",
      "Behavior 2.0: investigate_3\n",
      "114: allPossible\n",
      "114: andLongEnough\n",
      "79: andNotRepeated\n",
      "Percent valid: 69.3\n",
      "\n",
      "Behavior 3.0: rear\n",
      "35: allPossible\n",
      "35: andLongEnough\n",
      "30: andNotRepeated\n",
      "Percent valid: 85.7\n",
      "\n",
      "Behavior 4.0: dive_scrunch\n",
      "112: allPossible\n",
      "112: andLongEnough\n",
      "104: andNotRepeated\n",
      "Percent valid: 92.9\n",
      "\n",
      "Behavior 5.0: paw_groom\n",
      "74: allPossible\n",
      "74: andLongEnough\n",
      "45: andNotRepeated\n",
      "Percent valid: 60.8\n",
      "\n",
      "Behavior 6.0: face_groom_1\n",
      "157: allPossible\n",
      "157: andLongEnough\n",
      "106: andNotRepeated\n",
      "Percent valid: 67.5\n",
      "\n",
      "Behavior 7.0: face_groom_2\n",
      "60: allPossible\n",
      "60: andLongEnough\n",
      "38: andNotRepeated\n",
      "Percent valid: 63.3\n",
      "\n",
      "Behavior 8.0: head_groom\n",
      "66: allPossible\n",
      "66: andLongEnough\n",
      "36: andNotRepeated\n",
      "Percent valid: 54.5\n",
      "\n",
      "Behavior 9.0: contra_body_groom\n",
      "37: allPossible\n",
      "37: andLongEnough\n",
      "23: andNotRepeated\n",
      "Percent valid: 62.2\n",
      "\n",
      "Behavior 10.0: ipsi_body groom\n",
      "73: allPossible\n",
      "73: andLongEnough\n",
      "43: andNotRepeated\n",
      "Percent valid: 58.9\n",
      "\n",
      "Behavior 11.0: contra_itch\n",
      "95: allPossible\n",
      "95: andLongEnough\n",
      "70: andNotRepeated\n",
      "Percent valid: 73.7\n",
      "\n",
      "Behavior 12.0: ipsi_itch_1\n",
      "103: allPossible\n",
      "103: andLongEnough\n",
      "75: andNotRepeated\n",
      "Percent valid: 72.8\n",
      "\n",
      "Behavior 13.0: contra_orient\n",
      "288: allPossible\n",
      "288: andLongEnough\n",
      "222: andNotRepeated\n",
      "Percent valid: 77.1\n",
      "\n",
      "Behavior 14.0: ipsi_orient\n",
      "365: allPossible\n",
      "365: andLongEnough\n",
      "262: andNotRepeated\n",
      "Percent valid: 71.8\n",
      "\n",
      "Behavior 15.0: locomotion\n",
      "743: allPossible\n",
      "743: andLongEnough\n",
      "295: andNotRepeated\n",
      "Percent valid: 39.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "codes = np.unique(dataBhv.bhvID)\n",
    "behaviors = []  # behaviors: a Python list containing the behavior names\n",
    "for iBhv in range(len(codes)):\n",
    "    # first_idx = np.where(dataBhv['bhvID'] == codes[iBhv])[0][0]\n",
    "    firstIdx = np.where(dataBhv['bhvID'] == codes[iBhv])[0][0]\n",
    "    behaviors.append(dataBhv['bhvName'].iloc[firstIdx])\n",
    "\n",
    "opts.behaviors = behaviors\n",
    "opts.bhvCodes = codes\n",
    "opts.validCodes = np.array(codes)[np.array(codes) != -1]\n",
    "\n",
    "# Select valid behaviors\n",
    "valiBhv = behavior_selection(dataBhv, opts)\n",
    "opts.valid_bhv = valiBhv\n",
    "# all_valid = np.sum(np.array(valiBhv), axis=1)  # A list of all the valid behavior indices\n",
    "\n",
    "rmv_bhv = np.zeros(len(behaviors), dtype=int)\n",
    "for i in range(len(behaviors)):\n",
    "    if np.sum(valiBhv[:,i]) < 20:\n",
    "        rmv_bhv[i] = 1\n",
    "\n",
    "analyzeBhv = np.array(behaviors)[rmv_bhv == 0]\n",
    "analyzeCodes = np.array(codes)[rmv_bhv == 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keeping 142 of 376 neurons\n",
      "17 M23\n",
      "28 M56\n",
      "63 DS\n",
      "34 VS\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "opts.dataPath = nrnDataPath\n",
    "data = load_data(opts, 'neuron')\n",
    "# data.bhvDur = dataBhv.bhvDur\n",
    "data[\"bhvDur\"] = dataBhv.bhvDur\n",
    "# spikeTimes = data.spikeTimes\n",
    "# spikeClusters = data.spikeClusters\n",
    "\n",
    "\n",
    "# Find neuron clusters (ids) in each brain region\n",
    "allGood = (data['ci'].group.values == 'good') & (data['ci'].KSLabel.values == 'good')\n",
    "\n",
    "goodM23 = allGood & (data['ci'].area == 'M23')\n",
    "goodM56 = allGood & (data['ci'].area == 'M56')\n",
    "goodCC = allGood & (data['ci'].area == 'CC')\n",
    "goodDS = allGood & (data['ci'].area == 'DS')\n",
    "goodVS = allGood & (data['ci'].area == 'VS')\n",
    "\n",
    "opts.useNeurons = np.where(goodM23 | goodM56 | goodDS | goodVS)[0]\n",
    "\n",
    "a = [np.sum(goodM23), np.sum(goodM56), np.sum(goodCC), np.sum(goodDS), np.sum(goodVS)]\n",
    "np.sum(a)\n",
    "\n",
    "# Make or load neural matrix\n",
    "opts.useNeurons = np.where(goodM23 | goodM56 | goodDS | goodVS)[0]\n",
    "\n",
    "dataMat, idLabels, areaLabels, removedNeurons = neural_matrix(data, opts)  # Change rrm_neural_matrix\n",
    "\n",
    "idM23 = np.where(np.array(areaLabels) == 'M23')[0]\n",
    "idM56 = np.where(np.array(areaLabels) == 'M56')[0]\n",
    "idDS = np.where(np.array(areaLabels) == 'DS')[0]\n",
    "idVS = np.where(np.array(areaLabels) == 'VS')[0]\n",
    "\n",
    "print(f'{len(idM23)} M23\\n{len(idM56)} M56\\n{len(idDS)} DS\\n{len(idVS)} VS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 142)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 230)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataMat.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
